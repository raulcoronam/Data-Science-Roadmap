# M√≥dulo 3: Big Data and Data Mining

Este m√≥dulo se sumerge en la infraestructura que hace posible la ciencia de datos a gran escala. Aqu√≠ documentar√© mi aprendizaje sobre Cloud, Big Data y las herramientas y t√©cnicas para "minar" valor de conjuntos de datos masivos.

## üéØ Mi Objetivo con este M√≥dulo

* **¬øQu√© s√© ya sobre esto?** (Ej: "He o√≠do 'Big Data' mil veces, pero no s√© qu√© lo define. 'Cloud' es como Google Drive, pero para empresas. 'Hadoop' y 'Spark' son nombres que he visto, pero no s√© qu√© hacen.")
* **¬øCu√°l es mi meta de aprendizaje?** (Ej: "Quiero entender por qu√© un Data Scientist no puede usar solo su laptop. ¬øCu√°ndo se vuelve 'Big Data' un problema? Y quiero entender la diferencia fundamental entre Hadoop, Spark y el 'Data Mining'.")
* **¬øQu√© estrategia utilizar√©?** El M√©todo de Deconstrucci√≥n Aplicada 2.0.

---

## Paso 1: Vistazo al Resultado Final - El Caso de Meta (Facebook)

Para entender "Big Data" y "Data Mining", he analizado a uno de sus pioneros y mayores usuarios: Meta. Ellos se enfrentaron a problemas de escala tan grandes que tuvieron que inventar sus propias herramientas.

### An√°lisis Guiado

* **El Problema de Negocio:**
    1.  **Para Usuarios:** Filtrar miles de publicaciones para mostrar solo el contenido m√°s relevante en el News Feed y retener la atenci√≥n del usuario.
    2.  **Para Anunciantes:** Permitir una segmentaci√≥n h√≠per-espec√≠fica para que las marcas muestren anuncios solo a las audiencias que les interesan (ej. "mujeres de 30-40 que les gusta el yoga").

* **Los Datos (El "Big Data"):** Aqu√≠ es donde las "3 V" son obvias:
    * **Volumen:** Petabytes de datos (trillones de posts, likes, fotos, videos).
    * **Velocidad:** Millones de nuevos datos (likes, comentarios, shares) generados por segundo.
    * **Variedad:** Datos estructurados (perfil), no estructurados (fotos, texto) y semi-estructurados (logs de clics).

* **El Resultado Observable (El Producto de "Data Mining"):**
    1.  **El News Feed:** Es un producto de "miner√≠a de datos" que predice qu√© publicaciones te interesar√°n m√°s.
    2.  **Los Anuncios Segmentados:** El resultado de "minar" los perfiles y comportamientos de miles de millones de usuarios para agruparlos en audiencias vendibles.
    3.  **"Gente que podr√≠as conocer":** Un algoritmo de miner√≠a de datos que analiza las redes sociales.

### Conexi√≥n con las Herramientas del M√≥dulo
La √∫nica forma de lograr esto es con herramientas de Big Data:
* **Cloud:** No se usa una sola supercomputadora, sino un cl√∫ster de miles de m√°quinas baratas. Este conjunto de m√°quinas es la "nube".
* **HDFS (Hadoop File System):** Es el "disco duro" de la nube. Un sistema de archivos que reparte esos petabytes de datos entre todas las m√°quinas del cl√∫ster.
* **Hadoop (MapReduce) y Spark:** Son los "cerebros" del procesamiento. Permiten ejecutar una tarea (ej: "contar todos los likes de 'hiking'") en todas las miles de m√°quinas a la vez, en lugar de una por una. **Spark** es la versi√≥n moderna y m√°s r√°pida.
* **Hive:** La herramienta que Meta *invent√≥* para que sus Data Scientists pudieran usar lenguaje **SQL** (que ya sab√≠an) para lanzar trabajos de **Hadoop/Spark** (que eran muy complejos de programar), haciendo el an√°lisis de Big Data accesible.

---

## Paso 2: Fundamentos Conectados a la Realidad

Aqu√≠ documentar√© mis notas de cada lecci√≥n, conect√°ndolas siempre con el caso de Meta.

### üé• "How Big Data is Driving Digital Transformation"
La transformaci√≥n digital afecta a las operaciones comerciales, actualizando los procesos y operaciones existentes y creando otros nuevos para aprovechar los beneficios de las nuevas tecnolog√≠as. La transformaci√≥n digital no consiste simplemente en duplicar los procesos existentes en formato digital; el an√°lisis en profundidad del funcionamiento de la empresa ayuda a las organizaciones a descubrir c√≥mo mejorar sus procesos y operaciones, y a aprovechar las ventajas de integrar la ciencia de datos en sus flujos de trabajo. No cabe duda de que abordar todos los problemas que surgen en este esfuerzo requiere una nueva mentalidad, pero la transformaci√≥n digital es la forma de tener √©xito ahora y en el futuro. 
* **Conexi√≥n con el Caso Pr√°ctico:**
En 2018, los Rockets de Houston, un equipo de la NBA, elevaron su nivel de juego con el uso del big data. Los Rockets fueron uno de los cuatro equipos de la NBA que instalaron un sistema de seguimiento por v√≠deo que extra√≠a datos sin procesar de los partidos. Analizaron los datos de seguimiento de v√≠deo para investigar qu√© jugadas ofrec√≠an las mejores oportunidades de conseguir puntuaciones altas y descubrieron algo sorprendente. El an√°lisis de los datos revel√≥ que los tiros que ofrecen las mejores oportunidades de conseguir puntuaciones altas son los mates de dos puntos desde dentro de la zona de dos puntos y los tiros de tres puntos desde fuera de la l√≠nea de tres puntos, no los tiros de dos puntos a larga distancia desde dentro de la misma. Este descubrimiento cambi√≥ por completo la forma en que el equipo abordaba cada partido, aumentando el n√∫mero de intentos de tiros de tres puntos. En la temporada 2017-18, los Rockets encestaron m√°s tiros de tres puntos que ning√∫n otro equipo en la historia de la NBA, y esta fue una de las principales razones por las que ganaron m√°s partidos que cualquiera de sus rivales.

### üé• "Introduction to Cloud" / "Cloud for Data Science"
¬øQu√© es Cloud Computing? 
Es la entrega de recursos commputacionales bajo demanda, como redes, servidores, almacenamiento, aplicaciones, servicios, centros de datos, todo sobre internet y bajo un sistema de pago por uso. A Cloud Computing se accede mediante internet en vez de localmente. 

La computaci√≥n en la nube se compone de cinco caracter√≠sticas esenciales, tres modelos de implementaci√≥n y tres modelos de servicio. La computaci√≥n en la nube se compone de cinco caracter√≠sticas esenciales, tres modelos de implementaci√≥n y tres modelos de servicio.

Las 5 caracteristicas esenciales son: 
- On-demand self-service: Se puede acceder a los recursos de la nube mediante una interfaz sencilla sin necesidad de   interacci√≥n humana con cada proveedor de servicios.
- Broad network access: El amplio acceso a la red significa que a trav√©s de la red se pueden acceder a los recursos de cloud computing en tel√©fonos m√≥viles, tabletas, computadoras y estaciones de trabajo.
- Resource pooling: La agrupaci√≥n de recursos es lo que le da a los proveedores de la nube econom√≠a de escala, haciendo que la nube sea rentable. Al utilizar un modelo multiusuario, los recursos inform√°ticos se agrupan para atender a varios consumidores, y los recursos en la nube se asignan y reasignan din√°micamente seg√∫n la demanda, sin que los clientes necesiten saber la ubicaci√≥n f√≠sica de estos recursos. El "resource pooling" es como un gran dep√≥sito de recursos que se comparte entre diferentes usuarios. Imagina que tienes un grupo de amigos y todos deciden usar una piscina comunitaria. En lugar de que cada uno tenga su propia piscina en casa, todos pueden disfrutar de la misma piscina cuando lo deseen. De esta manera, se aprovechan mejor los recursos y se reduce el costo para cada uno. En el contexto de la computaci√≥n en la nube, los proveedores agrupan recursos como servidores, almacenamiento y redes para servir a m√∫ltiples clientes al mismo tiempo. Esto permite que los costos sean m√°s bajos y que los recursos se utilicen de manera m√°s eficiente.
- Rapid elasticity: Implica que puede acceder a m√°s recursos cuando los necesita y reducirlos cuando no los necesita, ya que los recursos se aprovisionan y liberan de forma el√°stica.
- Measured service: Significa que solo paga por lo que usa o reserva sobre la marcha. Si no utilizas los recursos, no pagas.

Los 3 modelos de implementaci√≥n de la nube indican donde reside la infraestructura, a qui√©n le pertenece, quien la maneja y c√≥mo se ponen a disposici√≥n de los usuarios los recursos y servicios de la nube y son: 
- P√∫blicos: Es cuando t√∫ aprovechas los servicios de la nube a trav√©s de internet abierto en hardware propiedad del proveedor de la nube, pero otras empresas comparten su uso. 
- Privados: La infraestructura de la nube se aprovisiona para el uso exclusivo de una sola organizaci√≥n. Puede funcionar de forma local o puede ser propiedad de un proveedor de servicios, gestionado y operado por √©l. 
- H√≠bridos: Es cuando se utikiza una combinaci√≥n de nubes p√∫blicas y privadas que funcionan juntas sin problemas.

Los 3 modelos de servicio se basan en las 3 capas de un conjunto de computaci√≥n: Infraestructura, Plataforma y Aplicaci√≥n, y son los siguientes: 

- Iaas (infraestructura como servicio): En un modelo de IaaS, puede acceder a la infraestructura y a los recursos inform√°ticos f√≠sicos, como los servidores, las redes, el almacenamiento y el espacio del centro de datos, sin necesidad de administrarlos ni operarlos. Think of this as renting a fully equipped workshop. You get access to all the tools and machines (like servers and storage) you need to build your projects, but you don‚Äôt have to worry about maintaining the workshop itself. You can use the resources as you need them and pay only for what you use.
- PaaS (plataforma como servicio): En un modelo PaaS, puede acceder a la plataforma que incluye las herramientas de hardware y software que normalmente se necesitan para desarrollar e implementar aplicaciones para los usuarios a trav√©s de Internet. This is like renting a space in a bakery where you can bake your cakes. The bakery provides the ovens, ingredients, and tools, so you can focus on creating delicious treats without worrying about the setup. In PaaS, you get the tools and environment to develop and deploy applications without managing the underlying infrastructure.
- SaaS (software como servicio): SaaS es un modelo de licencia y entrega de software en el que el software y las aplicaciones se alojan de forma centralizada y se licencian mediante suscripci√≥n. Imagine subscribing to a streaming service like Netflix. You can watch movies and shows without needing to download or install anything on your device. SaaS works the same way; you access software applications over the Internet, usually through a subscription, without needing to install them on your computer.

Diferencias: 
- IaaS: Control total sobre la infraestructura, ideal para empresas que necesitan personalizaci√≥n.
- PaaS: Enfoque en el desarrollo de aplicaciones, sin preocuparse por la infraestructura.
- SaaS: Acceso a aplicaciones listas para usar, sin necesidad de instalaci√≥n.

La nube es una "bendici√≥n" para los data scientist ya que pueden almacenar ah√≠ no solo grandes conjuntos de datos sino tambi√©n los algoritmos que usar√°n para trabajar dichos conjuntos de datos. La nube √®rmite que varias entidades de trabajo, trabajen con los mismos datos, al mismo tiempo, por ejemplo, colegas de Alemania, India y Ghana pueden trabajar de forma colectiva ya que la informaci√≥n, algoritmos, herramientas, respuestas, resultados y todo lo qye necesiten, est√°n disponibles en un lugar central (nube) y tambi√©n esta permite acceso instant√°neo a las tecnolog√≠as. 


### üé• "Foundations of Big Data"

Los macrodatos (big data) se refieren a los vol√∫menes de datos din√°micos, grandes y dispares que crean las personas, las herramientas y las m√°quinas. Requiere una tecnolog√≠a nueva, innovadora y escalable para recopilar, alojar y procesar anal√≠ticamente la gran cantidad de datos recopilados a fin de obtener informaci√≥n empresarial en tiempo real relacionada con los consumidores, el riesgo, las ganancias, el rendimiento, la gesti√≥n de la productividad y el aumento del valor para los accionistas. Las caracter√≠sticas que tienen en com√∫n todas las definiciones de big data son the V¬¥s of Big Data: 
- Velocity -> The speed at which data accumulates. 
- Volume -> The scale of the data. Sus drivers son:
        - Aumento en las fuentes de datos.
        - Sensores de mayor resoluci√≥n.
        - Infraestructura escalable.
- Variety -> Diversity of the data and also reflects that data comes from different sources. 
- Veracity -> Is the quality and origin of data and its conformity to facts and accuracy. Se considera que el 80% de los datos son no estructurados, por lo que debemos idear formas de generar informacion fiable y precisa. Sus drivers son: 
        - Costos asociados. A medida que se recopilan y almacenan grandes vol√∫menes de datos, los costos de asegurar         la calidad y la precisi√≥n de esos datos pueden aumentar. Las organizaciones deben invertir en herramientas y         procesos para verificar la veracidad de la informaci√≥n.
        - Necesidad de trazabilidad. Esto implica la capacidad de rastrear el origen de los datos y c√≥mo han sido             manipulados a lo largo del tiempo. La trazabilidad es crucial para garantizar que los datos sean precisos y          confiables, especialmente en entornos donde las decisiones se basan en esos datos.
- Value -> Our ability and need to turn data into value. Value is not just profit, also is social benefit. 

Tools such as Apache Spark, Hadoop and its ecosystem provide ways to extract, load, analyze and process the data across distributed compute resources. 

Una de las ventajas de los clusters de Big Data es que son escalables linealmente, es decir, si tu tienes el doble de servidores, tienes el doble de rendimiento. 

Procesos para manejar grandes cantidades de datos de manera eficiente:
      - Map or Mapper Process: Imagina que tienes un gran libro y quieres contar cu√°ntas veces aparece cada palabra. En el proceso Map, divides el libro en varias p√°ginas y le das una p√°gina a cada amigo. Cada amigo cuenta las palabras en su p√°gina y anota cu√°ntas veces aparece cada una. As√≠, en lugar de contar todas las palabras de una vez, cada amigo trabaja en su parte y env√≠a sus resultados.
      - Reduce process: Ahora que todos tus amigos han contado las palabras en sus p√°ginas, es hora de juntar toda esa informaci√≥n. En el proceso Reduce, t√∫ tomas las cuentas de cada amigo y las sumas. Por ejemplo, si un amigo cont√≥ "gato" 3 veces y otro amigo 5 veces, t√∫ sumas esos n√∫meros y obtienes que "gato" aparece 8 veces en total. Este proceso organiza y simplifica los resultados para que puedas ver el total de cada palabra en el libro.

* **Conexi√≥n con el Caso Pr√°ctico:**
    * **Volumen (Meta):** Petabytes de fotos, videos y posts.
    * **Velocidad (Meta):** Millones de 'likes', comentarios y mensajes por segundo.
    * **Variedad (Meta):** Texto (posts), im√°genes (fotos), video, datos estructurados (tu perfil).

### üé• "Big Data Processing Tools: Hadoop, HDFS, Hive, and Spark"
Estas herramientas proveen de formas de trabajar con grandes conjuntos de datos estructurados, semi estructurados y no estructurados para aprovechar el valor de big data. 

* **Apache Hadoop**

Distributed Storage and Processing: Hadoop allows for the storage and processing of large datasets across clusters of computers, providing a reliable and scalable solution.
Hadoop Distributed File System (HDFS): HDFS partitions files across multiple nodes, enabling parallel access and fault tolerance through data replication. Uso: Ideal para almacenar y procesar grandes vol√∫menes de datos de manera distribuida.

* **Apache Hive**

Data Warehousing: Hive is designed for reading, writing, and managing large datasets stored in HDFS, using SQL-like queries for data analysis.
High Latency: While suitable for ETL and reporting tasks, Hive is less appropriate for applications requiring fast response times due to its read-based nature. Uso: Mejor para tareas de an√°lisis de datos y generaci√≥n de informes, no para procesamiento en tiempo real.

* **Apache Spark**

Real-Time Data Processing: Spark is a general-purpose data processing engine that excels in real-time analytics and complex data processing.
In-Memory Processing: It significantly speeds up computations by processing data in memory and supports various programming languages, making it versatile for different applications. Uso: Ideal para an√°lisis en tiempo real, procesamiento de flujos de datos y machine learning.


### üìñ "Data Mining"
El primer paso en la extracci√≥n de datos requiere que se establezcan metas par el ejercicio. Obviamente, debes identificar las preguntas clave que necesitan ser respondidas. Adem√°s de tener en cuenta los costos y beneficios del ejercicio, debes determinar por adelantado el nivel esperado de exactitud y utilidad de los resultados obtenidos de la extracci√≥n de datos. 
    - Selecting Data 
    - Preprocessing Data
    - Transforming Data
    - Storing Data
    - Mining Data
    - Evaluating Mining Results 
* **Conexi√≥n con el Caso Pr√°ctico:** (Ej: "El **Data Mining** es lo que hace Meta para decidir qu√© anuncio mostrarme. 'Mina' mis likes, posts y los de mis amigos para clasificarme en un grupo (ej: 'persona interesada en hiking'). As√≠, las marcas de botas de monta√±a pueden pagarme para mostrarme su anuncio.")

---

## Glosario del M√≥dulo: Big Data y Data Mining

¬°Bienvenido! Este glosario contiene muchos de los t√©rminos de esta lecci√≥n. Es importante que reconozcas estos t√©rminos cuando trabajes en la industria, participes en grupos de usuarios y en otros programas de certificaci√≥n.

| Term | Definition | Video where the term is introduced |
| --- | --- | --- |
| Analytics | The process of examining data to draw conclusions and make informed decisions is a fundamental aspect of data science, involving statistical analysis and data-driven insights. | Data Scientists at New York University |
| Big Data | Vast amounts of structured, semi-structured, and unstructured data are characterized by its volume, velocity, variety, veracity and value, which, when analyzed, can provide competitive advantages and drive digital transformations. | How Big Data is Driving Digital Transformation |
| Big Data Cluster | A distributed computing environment comprising thousands or tens of thousands of interconnected computers that collectively store and process large datasets. | What is Hadoop? |
| Broad Network Access | The ability to access cloud resources via standard mechanisms and platforms such as mobile devices, laptops, and workstations over networks. | Introduction to Cloud |
| Chief Data Officer (CDO) | An emerging role responsible for overseeing data-related initiatives, governance, and strategies, ensuring that data plays a central role in digital transformation efforts. | How Big Data is Driving Digital Transformation |
| Chief Information Officer (CIO) | An executive is responsible for managing an organization's information technology and computer systems, contributing to technology-related aspects of digital transformation. | How Big Data is Driving Digital Transformation |
| Cloud Computing | The delivery of on-demand computing resources, including networks, servers, storage, applications, services, and data centers, over the Internet on a pay-for-use basis. | Introduction to Cloud |
| Cloud Deployment Models | Categories that indicate where cloud infrastructure resides, who manages it, and how cloud resources and services are made available to users, including public, private, and hybrid models. | Introduction to Cloud |
| Cloud Service Models | Models based on the layers of a computing stack, including Infrastructure as a Service (IaaS), Platform as a Service (PaaS), and Software as a Service (SaaS), represent different cloud computing offerings. | Introduction to Cloud |
| Commodity Hardware | Standard, off-the-shelf hardware components are used in a big data cluster, offering cost-effective solutions for storage and processing without relying on specialized hardware. | What is Hadoop? |
| Data Algorithms | Computational procedures and mathematical models used to process and analyze data made accessible in the cloud for data scientists to deploy on large datasets efficiently. | Cloud for Data Science |
| Data Replication | A strategy in in which data is duplicated across multiple nodes in a cluster to ensure data durability and availability, reducing the risk of data loss due to hardware failures. | What is Hadoop? |
| Data Science | An interdisciplinary field that involves extracting insights and knowledge from data using various techniques, including programming, statistics, and analytical tools. | Data Scientists at New York University |
| Deep Learning | A subset of machine learning that involves artificial neural networks inspired by the human brain, capable of learning and making complex decisions from data on their own. | Data Scientists at New York University |
| Digital Change | The integration of digital technology into business processes and operations leads to improvements and innovations in how organizations operate and deliver value to customers. | How Big Data is Driving Digital Transformation |
| Digital Transformation | A strategic and cultural organizational change driven by data science, especially Big Data, to integrate digital technology across all areas of the organization, resulting in fundamental operational and value delivery changes. | How Big Data is Driving Digital Transformation |
| Distributed Data | The practice of dividing data into smaller chunks and distributing them across multiple computers within a cluster enables parallel processing for data analysis. | What is Hadoop? |
| Hadoop | A distributed storage and processing framework used for handling and analyzing large datasets, particularly well-suited for big data analytics and data science applications. | Data Scientists at New York University |
| Hadoop Distributed File System (HDFS) | A storage system within the Hadoop framework that partitions and distributes files across multiple nodes, facilitating parallel data access and fault tolerance. | What is Hadoop? |
| Infrastructure as a Service (IaaS) | A cloud service model that provides access to computing infrastructure, including servers, storage, and networking, without the need for users to manage or operate them. | Introduction to Cloud |
| Java-Based Framework | Hadoop is implemented in Java, an open-source, high-level programming language, providing the foundation for building distributed storage and processing solutions. | Big Data Processing Tools: Hadoop, HDFS, Hive, and Spark |
| Map Process | The initial step in Hadoop's MapReduce programming model, where data is processed in parallel on individual cluster nodes, often used for data transformation tasks. | What is Hadoop? |
| Measured Service | A characteristic where users are billed for cloud resources based on their actual usage, with resource utilization transparently monitored, measured, and reported. | Introduction to Cloud |
| On-Demand Self-Service | The capability for users to access and provision cloud resources such as processing power, storage, and networking using simple interfaces without human interaction with service providers. | Introduction to Cloud |
| Rapid Elasticity | The ability to quickly scale cloud resources up or down based on demand, allowing users to access more resources when needed and release them when not in use. | Introduction to Cloud |
| Reduce Process | The second step in Hadoop's MapReduce model is where results from the mapping process are aggregated and processed further to produce the final output, typically used for analysis. | What is Hadoop? |
| Replication | The act of creating copies of data pieces within a big data cluster enhances fault tolerance and ensures data availability in case of hardware or node failures. | What is Hadoop? |
| Resource Pooling | A cloud characteristic where computing resources are shared and dynamically assigned to multiple consumers, promoting economies of scale and cost-efficiency. | Introduction to Cloud |
| Skills Network Labs (SN Labs) | Learning resources provided by IBM, including tools like Jupyter Notebooks and Spark clusters, are available to learners for cloud data science projects and skill development. | Cloud for Data Science |
| Spilling to Disk | A technique used in memory-constrained situations where data is temporarily written to disk storage when memory resources are exhausted, ensuring uninterrupted processing. | Big Data Processing Tools: Hadoop, HDFS, Hive, and Spark |
| STEM Classes | Science, Technology, Engineering, and Mathematics (STEM) courses typically taught in high schools prepare students for technical careers, including data science. | Data Scientists at New York University |
| Variety | The diversity of data types, including structured and unstructured data from various sources such as text, images, video, and more, posing data management challenges. | Foundations of Big Data |
| Velocity | The speed at which data accumulates and is generated, often in real-time or near-real-time, drives the need for rapid data processing and analytics. | Foundations of Big Data |
| Veracity | The quality and accuracy of data, ensuring that it conforms to facts and is consistent, complete, and free from ambiguity, impacts data reliability and trustworthiness. | Foundations of Big Data |
| Video Tracking System | A system used to capture and analyze video data from games, enabling in-depth analysis of player movements and game dynamics, contributing to data-driven decision-making in sports. | How Big Data is Driving Digital Transformation |
| Volume | The scale of data generated and stored is driven by increased data sources, higher-resolution sensors, and scalable infrastructure. | Foundations of Big Data |
| V's of Big Data | A set of characteristics common across Big Data definitions, including Velocity, Volume, Variety, Veracity, and Value, highlighting the rapid generation, scale, diversity, quality, and value of data. | Foundations of Big Data |

---

## üöÄ Conclusi√≥n del M√≥dulo

(Escribe tu reflexi√≥n final aqu√≠ cuando termines el m√≥dulo).
* **¬øQu√© funcion√≥ bien?**
* **¬øCu√°l es la diferencia clave que aprend√≠ entre Hadoop y Spark?**
* **¬øC√≥mo cambi√≥ mi entendimiento de 'Cloud'?**
