# Curso 2: Tools for Data Science
## M칩dulo 1: Visi칩n General de las Herramientas

Este m칩dulo es mi primera inmersi칩n en la "caja de herramientas" del Cient칤fico de Datos. El objetivo es entender el ecosistema de software que existe, por qu칠 hay tantas herramientas y en qu칠 categor칤a cae cada una.

## 游꿢 Mi Objetivo con este M칩dulo

* **쯈u칠 s칠 ya sobre esto?** (Ej: "He o칤do hablar de Python y R. Supongo que hay herramientas para 'Big Data' (como vi en el curso anterior) y herramientas para 'visualizar'. No tengo clara la diferencia entre 'Open Source', 'Cloud' y 'Comercial'.")
* **쮺u치l es mi meta de aprendizaje?** (Basado en los objetivos del m칩dulo) "Quiero poder describir el toolkit de un Data Scientist, listar las categor칤as de herramientas y dar ejemplos de Open Source (gratuitas), Comerciales (de paga) y Basadas en la Nube (Cloud)."
* **쯈u칠 estrategia utilizar칠?** El M칠todo de Deconstrucci칩n Aplicada 2.0.

---
## Paso 1: Vistazo al Resultado Final - El Caso de un E-commerce (Amazon/MercadoLibre)

Para entender por qu칠 existen tantas herramientas de Data Science, he deconstruido un proyecto com칰n: un **sistema de recomendaci칩n** ("Los clientes que compraron esto tambi칠n compraron...").

### An치lisis Guiado: El Viaje del Proyecto y su "Toolkit"

Un solo proyecto de datos pasa por m칰ltiples etapas, y cada una usa un tipo de herramienta diferente. No existe "una herramienta para todo".

* **El Problema de Negocio:** Aumentar el valor promedio del carrito de compras sugiriendo productos relevantes.

* **Las Herramientas (El "Toolkit" en Acci칩n):**
    1.  **La "Cantera" (Almacenamiento):** Primero, todos los datos de las compras se guardan en una base de datos.
        * **Herramienta:** **SQL**.
    2.  **El "Taller" (An치lisis):** Un Data Scientist explora y limpia millones de transacciones para entender los patrones de compra.
        * **Herramienta (Open Source):** **Jupyter Notebooks** y **Python** (con Pandas).
    3.  **El "Motor" (Modelado):** Se construye el algoritmo de ML que aprende los patrones y genera las recomendaciones.
        * **Herramienta (Open Source):** **Python** (con Scikit-learn).
    4.  **El "Dashboard" (Visualizaci칩n):** El gerente de marketing necesita ver el impacto en las ventas en un gr치fico.
        * **Herramienta (Comercial):** **Tableau** o **Power BI**.
    5.  **La "F치brica" (Despliegue):** El modelo debe funcionar para millones de usuarios en tiempo real en el sitio web, 24/7. No puede correr en una laptop.
        * **Herramienta (Cloud-based):** **IBM Watson Studio** o **AWS SageMaker**.

**Conclusi칩n del Paso 1:** Este caso me demuestra por qu칠 el curso divide las herramientas en categor칤as. Un Data Scientist exitoso no es un experto en *una* herramienta, sino que sabe *qu칠 tipo* de herramienta (Open Source, Comercial o Cloud) usar en *cada etapa* del proyecto, desde el "Taller" hasta la "F치brica".

## Paso 2: Fundamentos Conectados a la Realidad

## OpenSource tools: 

### Data management tools
  - MySQL: Is a open source RDBMS that uses Structured Query Language (SQL) para manipular y almacenar datos. Su uso com칰n es en web applications e e-commerce. 
  - PostgreSQL: Is a RDBMS que enfatiza en cumplimuento de extensibilidad y SQL, ofrece caracter칤sticas avanzadas como soporte a JSON, b칰squeda full text y spacial data. 
  - (apache) cassandra: Base de datos NoSQL altamente escalable y distribuida que puede lidiar con grandes cantidades de data estructurada y no estructurada. 
  - elasticsearch: REASTful search y motor de an치lisis altamente escalable y f치cil de usar con capacidades de consulta potentes. 
  - ceph: Is a open source storage platform dise침ado para data centers modernos.
  - CouchDB: Es un NoSQL orientado a documentos que usa JSON para almacenar datos. 
  - mongoDB: Es como CouchDB a modo para aplicaciones de web modernas que lidian con grandes vol칰menes de data no estructurada. 
  - Hadoop HDFS: Sistema de archivos que proporciona un alto rendimiento de acceso a datos de aplicaci칩n.

### Operating system tools
  - Jupyter: Es un IDE que soporta desarrollo en Julia, Python y R con Jupyter Notebook, Jupyter Lab y Jupyter Hub. Jupyter Lab incluye notebooks personalizados para organizaciones y JupyterHub extiende esas capacidades para empresas. 
  - RStudio: Es un IDE construida para gestionar y ejecutar c칩digo en R. 
  - Microsoft Visual Studio: IDE que soporta varios lenguajes como C, C++, C++/CLI, Visual Basic, .NET, C#, F#, JavaScript, TypeScript, XML, XSLT, HTML y CSS, as칤 como Python, Ruby, Node.js y M. 
  - Pycharm: IDE de suscripci칩n que ofrece m치s de 16 herramientas adicionales para codificar, asistencia, testeo y desarrollo. 
  - Spyder: IDE dise침ada para cient칤ficos, ingenieros y analistas de datos, incluye una combinaci칩n de herramientas de desarrollo integral para editado avanzado, analisis, depuraci칩n, etc. 
  - Anaconda Navigator: Is an GUI-based Navigator that supports Python development.

### Data integration and transformation tools
  - Apache Spark SQL: Es un m칩dulo del ecosistema Spark que proporciona una interfaz de programaci칩n para trabajar con structured data usando SQL, data frames y datasets.
  - Kubeflow: Es una caja de herramientas de machine learning construida sobre Kubernetes que proporciona una plataforma para construir, implementar y gestionar flujos de trabajo de machine learning end to end.
  - Node-RED: Es una herramienta de programaci칩n visual para conectar juntos hardware, APIs y servicios online.
  - Apache Airflow: Es una plataforma para program치ticamente crear, calendarizar y monitorear flujos de trabajo.
  - Apache Nifi: Es una platafora de integraci칩n que permite a los usuarios automatiar el flujo de datos entre sistemas.
  - Apache Kafka: Es una plataforma de flujos que permite a aplicaciones publicar, procesar y suscribir a flujos de registros en tiempo real.

### Data visualization tools
  -   Tableau and PowerBI are used for dara visualization, but data scientist use other tools.
  -   PixieDust: Es una librer칤a para crear visualizaciones exploratorias de datos en Python y Jupyter Notebooks.
  -   Kibana: Herramienta de visualizaci칩n que permite a los usuarios interactuar con su propia data a trav칠s de una interfaz basada en la web.
  -   Hue: Es una interfaz web para analizar y visualizar conjuntos de datos grandes en Apache Hadoop.
  -   Apache Superset: Es una aplicaci칩n web moderna para empresas que buscan inteligencia empresarial que hace f치cil de visualizar y explorar grandes datasets. 

### Model deployment tools
  - Apache PredictionIO: Es un servidor de machine learning construido sobre una infraestructura distribuida y escalable. 
  - Kubernetes: Plataforma de orquestraci칩n de contenedores que autom치icamente lanza, escala y gestiona aplicaciones contenidas. 
  - MLeap: Librer칤a para serializaci칩n y deserializaci칩n de modelos de aprendizaje en una en un archivo multiprop칩sito. Le da a los usuarios la habilidad de exportar modelos desde diferentes librer칤as y frameworks tales como Spark, scikit-learn y TensorFlow.
  - TensorFlow Lite: Es una herramienta para correr modelos de ML en dispositivos m칩viles y embebidos. 
  - Apache Seldon: Plataforma para implementar y gestionar ML models sobre Kubernetes. 
  - OpenShift: Container application framework basado en Kubernets con caracter칤sticas como automatizaci칩n ,escalabilidad y seguridad, ofrece un m칠todo para crear, implementar y gestionar containerized applications. 
  - TensorFlow Serving: Es una utilidad que sirve ML models en configuraciones del mundo real. 
  - TensorFlow.js: Librer칤a que sirve para construir e implementar ML models en JavaScript. 

### Model monitoring and assessment tools
  - IBM AI Fairness 360: Conjunto de herramientas para detectar y mitigar sesgo en modelos de ML.  
  - IBM AI Explainability 360: Conjunto de herramientas para explicar el comportamiento y decisiones de modelos de ML.
  - IBM Adversarial Robustness 360 Toolbox: Librer칤a para proteger ML models de ataques adversarios.  
  - Prometheus: Sistema de monitoreo que colecta y almacena m칠tricas en tiempo real desde distintas fuentes. 
  - ModelDB: Plataforma de gestion de ML models y experimentos.

### Code asset tools
  - Git: VCS para rastrear cambios en c칩digo y colaboraci칩n entre desarrolladores. 
  - GitLab: Es un repositorio web basado en Git que proporciona una completa plataforma de Operaciones de desarrollo.
  - GitHub: Repositorio web basado en Git que proporciona una plataforma para desarrolladores para colaborar en c칩digo y gestionar proyectos de software. 
  - Bitbucket: Es un VCS que proporciona a los desarrolladores una paltaforma para colaborar en c칩digo y gestionar proyectos de software.

### Data asset tools
  - ODPi Egeria es un framework de gestionamiento de metadata que proporciona una manera est치ndar de gestionar y compartir metadatos a trav칠s de diferentes plataformas y herramientas.
  - Kylo: Es una plataforma dise침ada para simplificar los procesos de datos.
  - Apache Atlas: Framework de gestionamiento y gobernanza de metadatos para ecosistemas Hadoop. 

## Comercial tools: 
Data Management Tools

Key players include Oracle Database, Microsoft SQL Server, and IBM Db2, which are considered industry standards.
Commercial support from vendors is crucial for effective data management.
Data Integration Tools

Leaders in this category are Informatica PowerCenter and IBM InfoSphere DataStage, along with SAP, Oracle, and Microsoft products.
These tools facilitate the design and deployment of ETL (Extract, Transform, Load) processes through graphical interfaces.
Data Visualization and Model Building Tools

Prominent visualization tools include Tableau, Microsoft Power BI, and IBM Cognos Analytics, aimed at creating reports and dashboards.
For model building, SPSS Modeler and SAS Enterprise Miner are highlighted, with SPSS Modeler also available in Watson Studio Desktop for cloud-based applications.
---

# 游빓 Caja de Herramientas del Cient칤fico de Datos

A continuaci칩n se presenta un desglose de las categor칤as de herramientas esenciales y ejemplos populares dentro de cada una.

---

## 1. Herramientas de Gesti칩n de Datos (Data Management)
*Facilita el almacenamiento, la organizaci칩n y la recuperaci칩n de datos. Incluye bases de datos relacionales, NoSQL y plataformas de Big Data.*

### MySQL
* Popular sistema de gesti칩n de bases de datos relacionales (RDBMS) de c칩digo abierto.
* Utiliza SQL (Structured Query Language) para gestionar y almacenar datos.
* **Usos comunes:** Aplicaciones web, Data Warehousing, E-commerce.

### PostgreSQL
* Potente sistema de gesti칩n de bases de datos relacionales (RDBMS) de c칩digo abierto.
* Enfatiza la extensibilidad y el cumplimiento de SQL.
* **Ofrece caracter칤sticas avanzadas como:** Soporte para JSON, b칰squeda de texto completo, datos espaciales.

### Apache CouchDB
* Base de datos NoSQL orientada a documentos.
* Utiliza JSON para almacenar datos.
* Altamente escalable, tolerante a fallos y f치cil de usar.

### MongoDB
* Base de datos NoSQL orientada a documentos.
* Almacena datos en un formato JSON flexible.
* **Proporciona:** Escalabilidad, alta disponibilidad y distribuci칩n de datos.
* **Adecuado para:** Aplicaciones web modernas que manejan grandes vol칰menes de datos no estructurados.

### Apache Cassandra
* Base de datos NoSQL orientada a documentos, distribuida y altamente escalable.
* Puede manejar grandes cantidades de datos estructurados y no estructurados a trav칠s de muchos servidores b치sicos.
* **Ofrece:** Alta disponibilidad, tolerancia a fallos y niveles de consistencia ajustables.
* **Adecuado para:** Aplicaciones de misi칩n cr칤tica.

### Hadoop Distributed File System (HDFS)
* Dise침ado para trabajar con grandes conjuntos de datos (como Apache Hadoop) en un entorno de computaci칩n distribuida.
* Procesamiento de datos de alto rendimiento al dividir archivos en bloques (default 128MB), distribuidos en m칰ltiples DataNodes.
* Los datos se replican en diferentes DataNodes, asegurando alta disponibilidad y tolerancia a fallos.
* Escalable y eficiente.

### Ceph
* Plataforma de almacenamiento definida por software, gratuita y de c칩digo abierto, adecuada para entornos de nube h칤brida.
* Dise침ada para centros de datos modernos.
* Proporciona un sistema de almacenamiento unificado y altamente escalable para: almacenamiento de objetos (como AWS S3), almacenamiento en bloques (discos virtuales) y almacenamiento de archivos (como NFS).
* Alto rendimiento, disponibilidad y fiabilidad.

### Elasticsearch
* Principalmente un motor de b칰squeda y herramienta de an치lisis RESTful distribuido.
* Basado en la biblioteca Lucene.
* **Ofrece:** B칰squeda de texto completo, an치lisis de datos en tiempo real, alta escalabilidad.
* F치cil de usar, potentes capacidades de consulta e indexaci칩n de datos en tiempo real.

---

## 2. Herramientas de Integraci칩n y Transformaci칩n de Datos (ETL)
*Agiliza las canalizaciones de datos (data pipelines) y automatiza los flujos de trabajo de procesamiento. La tarea cl치sica es Extraer, Transformar y Cargar (ETL).*

### Apache Airflow
* Plataforma de c칩digo abierto para crear, programar y monitorear flujos de trabajo de forma program치tica.
* Creada originalmente por Airbnb.
* Permite a los usuarios definir y ejecutar flujos de trabajo complejos con soporte para dependencias, paralelismo y manejo de errores.

### Kubeflow
* Un conjunto de herramientas de machine learning de c칩digo abierto que permite la ejecuci칩n de pipelines de ciencia de datos sobre Kubernetes.
* Proporciona una plataforma para construir, desplegar y gestionar flujos de trabajo de ML de extremo a extremo a escala.
* **Soporte para:** Entrenamiento distribuido, servicio de modelos, ajuste de hiperpar치metros.

### Apache Kafka
* Plataforma de streaming distribuida que permite a las aplicaciones publicar, procesar y suscribirse a flujos de r칠cords en tiempo real.
* Creada originalmente por LinkedIn.
* Es escalable, tolerante a fallos y de alto rendimiento (high-throughput).
* **Adecuado para:** Construir aplicaciones de misi칩n cr칤tica e intensivas en datos.

### Apache NiFi
* Plataforma de integraci칩n de datos de c칩digo abierto que permite a los usuarios automatizar el flujo de datos entre sistemas.
* Proporciona una interfaz de usuario web para dise침ar y gestionar flujos de datos.
* **Soporte para:** Enrutamiento de datos, transformaci칩n, enriquecimiento y otras capacidades.

### Apache Spark SQL
* Un m칩dulo en el ecosistema de Spark que proporciona una interfaz de programaci칩n para trabajar con datos estructurados usando SQL, DataFrames y Datasets.
* Soporta una amplia gama de fuentes de datos y proporciona un rendimiento optimizado.

### Node-RED
* Herramienta de programaci칩n visual de c칩digo abierto para conectar dispositivos de hardware, APIs y servicios en l칤nea.
* Permite a los usuarios crear flujos de mensajes controlados por eventos.
* Su consumo de recursos es tan bajo que incluso funciona en dispositivos peque침os como una Raspberry Pi.
* **Soporte para:** Transformaci칩n, filtrado y agregaci칩n de datos.

---

## 3. Herramientas de Visualizaci칩n de Datos
*Proporciona una representaci칩n gr치fica de los datos y ayuda a comunicar los "insights" (hallazgos clave).*

### PixieDust
* Biblioteca de c칩digo abierto para crear visualizaciones de datos interactivas y exploratorias en Python y Jupyter notebooks.
* Proporciona visualizaciones integradas y conectores de datos.
* Soporta personalizaci칩n y extensibilidad.

### Hue
* Interfaz web de c칩digo abierto para analizar y visualizar grandes conjuntos de datos en Apache Hadoop.
* Ofrece una experiencia amigable para explorar datos y crear visualizaciones sin necesidad de habilidades de programaci칩n; puede crear visualizaciones desde consultas SQL.

### Kibana
* Herramienta de visualizaci칩n de datos de c칩digo abierto que permite a los usuarios interactuar con sus datos a trav칠s de una interfaz web.
* Com칰nmente usada con Elasticsearch para analizar y visualizar grandes conjuntos de datos.

### Apache Superset
* Una aplicaci칩n web de inteligencia de negocios (BI) moderna y lista para empresas que facilita la visualizaci칩n y exploraci칩n de grandes conjuntos de datos.
* Ofrece un rico conjunto de opciones de visualizaci칩n, incluyendo gr치ficos, tablas, mapas, an치lisis geoespacial y procesamiento de datos en tiempo real.

---

## 4. Herramientas de Despliegue de Modelos (Model Deployment)
*Soporta la construcci칩n y despliegue (puesta en producci칩n) de modelos de datos y machine learning.*

### Apache PredictionIO
* Servidor de machine learning de c칩digo abierto construido sobre una infraestructura escalable y distribuida.
* Permite a los desarrolladores construir, evaluar y desplegar r치pidamente motores predictivos para recomendaci칩n, clasificaci칩n,

## 游 Conclusi칩n del M칩dulo

(Escribe tu reflexi칩n final aqu칤 cuando termines el m칩dulo).
* **쯈u칠 funcion칩 bien?**
* **쮺u치l es la diferencia m치s clara que entend칤 entre herramientas Open Source, Cloud y Comerciales?**
* **쯇or qu칠 un Data Scientist no puede usar una sola herramienta para todo?**

---

## Glosario del M칩dulo
(Aqu칤 puedes pegar la tabla del glosario cuando la tengas).
